# Pipeline de Dados PÃºblicos com AWS Glue

Este repositÃ³rio contÃ©m um pipeline de dados construÃ­do na **AWS** para realizar processos de **ETL** (Extract, Transform, Load) em dados pÃºblicos.  
O projeto demonstra boas prÃ¡ticas no uso de serviÃ§os serverless como **S3**, **Glue**, **Athena** e **QuickSight**.

---

## ðŸ“š DescriÃ§Ã£o do Projeto

O pipeline realiza:

- **Coleta de dados pÃºblicos** em formato CSV/JSON.
- **Armazenamento bruto** no Amazon S3 (data lake).
- **TransformaÃ§Ã£o** com scripts em PySpark no AWS Glue (limpeza, normalizaÃ§Ã£o, enriquecimento).
- **Carga dos dados tratados** em formato otimizado (Parquet) em um bucket estruturado.
- **CatalogaÃ§Ã£o** no Glue Data Catalog para consultas rÃ¡pidas.
- **Consumo dos dados** via Amazon Athena e visualizaÃ§Ãµes no QuickSight.

---

## ðŸ—‚ Estrutura do RepositÃ³rio

pipeline-dados-publicos-aws-glue/
â”‚
â”œâ”€â”€ README.md # DocumentaÃ§Ã£o do projeto
â”œâ”€â”€ docs/ # Documentos e diagramas
â”‚ â””â”€â”€ diagrama_pipeline.png
â”œâ”€â”€ data/ # Exemplos de dados pÃºblicos
â”‚ â””â”€â”€ exemplo_dados.csv
â””â”€â”€ scripts/ # CÃ³digos do pipeline
â”œâ”€â”€ glue_jobs/ # Jobs do AWS Glue em PySpark
â”‚ â””â”€â”€ job_etl.py
â””â”€â”€ tests/ # Scripts de teste/validaÃ§Ã£o


---

## ðŸ›  PrÃ©-requisitos

- Conta AWS ativa.
- PermissÃµes para usar:
  - Amazon S3
  - AWS Glue
  - AWS Athena
  - (opcional) Amazon QuickSight para dashboards
- Python 3.x (para scripts locais ou testes).

---

## ðŸš€ Como Executar

1. **Clone o repositÃ³rio:**
   ```bash
   git clone https://github.com/seu-usuario/pipeline-dados-publicos-aws-glue.git
   cd pipeline-dados-publicos-aws-glue
aws configure
